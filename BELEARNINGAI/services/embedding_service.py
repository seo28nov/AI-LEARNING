"""
Embedding Service - Generate embeddings s·ª≠ d·ª•ng Google AI.

Service n√†y ch·ªãu tr√°ch nhi·ªám:
1. Generate embeddings cho course content (documents)
2. Generate embeddings cho user queries
3. Batch processing ƒë·ªÉ t·ªëi ∆∞u API calls
"""
from typing import List
import logging
import asyncio

import google.generativeai as genai
from config.config import settings

logger = logging.getLogger(__name__)


class EmbeddingService:
    """Service ƒë·ªÉ generate text embeddings v·ªõi Google AI."""
    
    # Constants
    EMBEDDING_MODEL = "models/embedding-001"  # Google AI embedding model
    EMBEDDING_DIMENSION = 768  # Dimension c·ªßa embedding vector
    MAX_BATCH_SIZE = 100  # Google AI gi·ªõi h·∫°n 100 texts/request
    
    def __init__(self):
        """
        Kh·ªüi t·∫°o Embedding Service.
        
        C·∫•u h√¨nh Google AI API key v√† model.
        """
        try:
            # C·∫•u h√¨nh Google AI
            genai.configure(api_key=settings.GOOGLE_API_KEY)
            
            logger.info("‚úÖ Embedding Service ƒë√£ s·∫µn s√†ng v·ªõi Google AI")
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói kh·ªüi t·∫°o Embedding Service: {e}")
            raise
    
    async def generate_embedding(self, text: str, task_type: str = "retrieval_document") -> List[float]:
        """
        Generate embedding cho m·ªôt ƒëo·∫°n text.
        
        Args:
            text: Text c·∫ßn generate embedding
            task_type: Lo·∫°i task:
                - "retrieval_document": Cho n·ªôi dung kh√≥a h·ªçc (documents)
                - "retrieval_query": Cho c√¢u h·ªèi t√¨m ki·∫øm (queries)
                - "semantic_similarity": Cho so s√°nh t∆∞∆°ng ƒë·ªìng
                
        Returns:
            List of floats (vector embedding v·ªõi 768 dimensions)
            
        Example:
            >>> embedding_service = EmbeddingService()
            >>> vector = await embedding_service.generate_embedding("Python l√† ng√¥n ng·ªØ l·∫≠p tr√¨nh")
            >>> len(vector)
            768
        """
        try:
            # Validate input
            if not text or not text.strip():
                logger.warning("‚ö†Ô∏è Text r·ªóng, tr·∫£ v·ªÅ zero vector")
                return [0.0] * self.EMBEDDING_DIMENSION
            
            # Truncate text n·∫øu qu√° d√†i (Google AI limit ~10k tokens)
            text = text[:10000]
            
            # Generate embedding
            result = genai.embed_content(
                model=self.EMBEDDING_MODEL,
                content=text,
                task_type=task_type
            )
            
            embedding = result["embedding"]
            
            logger.debug(f"‚úÖ Generated embedding: {len(embedding)} dimensions")
            
            return embedding
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói generate embedding: {e}")
            # Tr·∫£ v·ªÅ zero vector thay v√¨ raise exception
            return [0.0] * self.EMBEDDING_DIMENSION
    
    async def generate_embeddings_batch(
        self,
        texts: List[str],
        task_type: str = "retrieval_document"
    ) -> List[List[float]]:
        """
        Generate embeddings cho nhi·ªÅu texts (batch processing).
        
        T·ª± ƒë·ªông chia th√†nh batches nh·ªè ƒë·ªÉ tr√°nh v∆∞·ª£t qu√° API limit.
        
        Args:
            texts: List of texts c·∫ßn generate embeddings
            task_type: Lo·∫°i task (retrieval_document ho·∫∑c retrieval_query)
            
        Returns:
            List of embedding vectors
            
        Example:
            >>> texts = ["Text 1", "Text 2", "Text 3"]
            >>> embeddings = await embedding_service.generate_embeddings_batch(texts)
            >>> len(embeddings)
            3
        """
        try:
            if not texts:
                logger.warning("‚ö†Ô∏è Texts list r·ªóng")
                return []
            
            logger.info(f"üìä B·∫Øt ƒë·∫ßu generate embeddings cho {len(texts)} texts")
            
            all_embeddings = []
            
            # Chia th√†nh batches
            for i in range(0, len(texts), self.MAX_BATCH_SIZE):
                batch = texts[i:i + self.MAX_BATCH_SIZE]
                
                # Filter ra empty texts
                valid_texts = [t for t in batch if t and t.strip()]
                
                if not valid_texts:
                    # N·∫øu batch to√†n empty, th√™m zero vectors
                    all_embeddings.extend(
                        [[0.0] * self.EMBEDDING_DIMENSION] * len(batch)
                    )
                    continue
                
                # Truncate texts
                truncated_texts = [t[:10000] for t in valid_texts]
                
                try:
                    # Generate embeddings cho batch
                    result = genai.embed_content(
                        model=self.EMBEDDING_MODEL,
                        content=truncated_texts,
                        task_type=task_type
                    )
                    
                    # Extract embeddings
                    batch_embeddings = result["embedding"]
                    
                    # N·∫øu ch·ªâ c√≥ 1 text, wrap th√†nh list
                    if isinstance(batch_embeddings[0], float):
                        batch_embeddings = [batch_embeddings]
                    
                    all_embeddings.extend(batch_embeddings)
                    
                    logger.info(f"‚úÖ Batch {i // self.MAX_BATCH_SIZE + 1}: {len(batch_embeddings)} embeddings")
                    
                    # Delay nh·ªè ƒë·ªÉ tr√°nh rate limiting
                    if i + self.MAX_BATCH_SIZE < len(texts):
                        await asyncio.sleep(0.1)
                    
                except Exception as e:
                    logger.error(f"‚ùå L·ªói batch {i // self.MAX_BATCH_SIZE + 1}: {e}")
                    # Th√™m zero vectors cho batch b·ªã l·ªói
                    all_embeddings.extend(
                        [[0.0] * self.EMBEDDING_DIMENSION] * len(batch)
                    )
            
            logger.info(f"‚úÖ Ho√†n th√†nh generate {len(all_embeddings)} embeddings")
            
            return all_embeddings
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói generate embeddings batch: {e}")
            # Tr·∫£ v·ªÅ zero vectors
            return [[0.0] * self.EMBEDDING_DIMENSION] * len(texts)
    
    async def generate_query_embedding(self, query: str) -> List[float]:
        """
        Generate embedding cho search query.
        
        ƒê√¢y l√† helper function v·ªõi task_type="retrieval_query" ƒë√£ set s·∫µn.
        
        Args:
            query: C√¢u h·ªèi/query t·ª´ user
            
        Returns:
            Embedding vector
            
        Example:
            >>> query = "Python list comprehension l√† g√¨?"
            >>> embedding = await embedding_service.generate_query_embedding(query)
        """
        return await self.generate_embedding(query, task_type="retrieval_query")
    
    async def generate_document_embedding(self, text: str) -> List[float]:
        """
        Generate embedding cho document/content.
        
        ƒê√¢y l√† helper function v·ªõi task_type="retrieval_document" ƒë√£ set s·∫µn.
        
        Args:
            text: N·ªôi dung document
            
        Returns:
            Embedding vector
        """
        return await self.generate_embedding(text, task_type="retrieval_document")
    
    def compute_similarity(self, embedding1: List[float], embedding2: List[float]) -> float:
        """
        T√≠nh cosine similarity gi·ªØa 2 embeddings.
        
        Args:
            embedding1: Vector embedding th·ª© nh·∫•t
            embedding2: Vector embedding th·ª© hai
            
        Returns:
            Similarity score t·ª´ 0 ƒë·∫øn 1 (1 l√† gi·ªëng nh·∫•t)
            
        Example:
            >>> emb1 = await embedding_service.generate_embedding("Python")
            >>> emb2 = await embedding_service.generate_embedding("Java")
            >>> similarity = embedding_service.compute_similarity(emb1, emb2)
        """
        try:
            # Cosine similarity = dot product / (norm1 * norm2)
            import math
            
            # Dot product
            dot_product = sum(a * b for a, b in zip(embedding1, embedding2))
            
            # Norms
            norm1 = math.sqrt(sum(a * a for a in embedding1))
            norm2 = math.sqrt(sum(b * b for b in embedding2))
            
            # Avoid division by zero
            if norm1 == 0 or norm2 == 0:
                return 0.0
            
            # Cosine similarity
            similarity = dot_product / (norm1 * norm2)
            
            # Clamp to [0, 1]
            return max(0.0, min(1.0, similarity))
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói compute similarity: {e}")
            return 0.0
    
    async def test_connection(self) -> bool:
        """
        Test xem c√≥ th·ªÉ k·∫øt n·ªëi v√† generate embedding kh√¥ng.
        
        Returns:
            True n·∫øu test th√†nh c√¥ng, False n·∫øu th·∫•t b·∫°i
        """
        try:
            logger.info("üß™ Testing Embedding Service...")
            
            # Test v·ªõi text ƒë∆°n gi·∫£n
            test_text = "This is a test."
            embedding = await self.generate_embedding(test_text)
            
            # Verify embedding
            if len(embedding) == self.EMBEDDING_DIMENSION:
                logger.info("‚úÖ Embedding Service test th√†nh c√¥ng!")
                return True
            else:
                logger.error(f"‚ùå Embedding dimension sai: {len(embedding)}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Embedding Service test th·∫•t b·∫°i: {e}")
            return False


# ============================================================================
# SINGLETON INSTANCE
# ============================================================================

# Kh·ªüi t·∫°o embedding service duy nh·∫•t
try:
    embedding_service = EmbeddingService()
    logger.info("‚úÖ Embedding Service singleton ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o")
except Exception as e:
    logger.error(f"‚ùå Kh√¥ng th·ªÉ kh·ªüi t·∫°o Embedding Service: {e}")
    embedding_service = None
